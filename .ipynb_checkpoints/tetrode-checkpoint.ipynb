{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5caf6d76-5614-43ca-bae6-b181999cec00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording root: C:\\Users\\ryoi\\Documents\\SpikeSorting\\recordings\n",
      "KS4 out: C:\\Users\\ryoi\\Documents\\SpikeSorting\\ks4_outputs\n",
      "SC2 out: C:\\Users\\ryoi\\Documents\\SpikeSorting\\sc2_outputs\n"
     ]
    }
   ],
   "source": [
    "#%% 0) Imports, deterministic settings, user config\n",
    "\n",
    "import os, random, time, shutil\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "TEST_SECONDS = 60\n",
    "# ---- user config (edit these two) ----\n",
    "ROOT_DIR = Path(r\"C:/Users/ryoi/Documents/SpikeSorting/recordings\")\n",
    "SESSION_SUBPATH = Path(r\"2025-10-01_15-53-19/Record Node 125/experiment1/recording1\")\n",
    "# Optional: force a specific stream name, else auto-pick\n",
    "STREAM_NAME = None  # e.g. \"Record Node 125#Acquisition_Board-100.Rhythm Data\"\n",
    "\n",
    "# ---- determinism-ish (helps reduce run-to-run jitter) ----\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\"\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "# Outputs live here\n",
    "BASE_OUT = Path(r\"C:/Users/ryoi/Documents/SpikeSorting\")\n",
    "KS4_OUT = BASE_OUT / \"ks4_outputs\"\n",
    "SC2_OUT = BASE_OUT / \"sc2_outputs\"\n",
    "for d in (KS4_OUT, SC2_OUT): \n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Quick test slice (seconds) â€” set to None for full session\n",
    "\n",
    "# Known bad channels (use the same ID format as the recording)\n",
    "BAD = []  # e.g. [\"CH12\",\"CH59\"]\n",
    "# Geometry settings for nicer Phy plots (tetrode 2Ã—2 layout on a grid)\n",
    "ATTACH_GEOMETRY = True\n",
    "TETRODES_PER_ROW = 4  # 64 ch = 16 tetrodes â†’ 4Ã—4 layout looks tidy\n",
    "# Sorter toggles\n",
    "RUN_KS4 = True\n",
    "RUN_SC2 = True\n",
    "# KS4 device ('cpu' now; switch to 'cuda' when you have GPU PyTorch)\n",
    "KS4_TORCH_DEVICE = \"cpu\"\n",
    "print(\"Recording root:\", ROOT_DIR)\n",
    "print(\"KS4 out:\", KS4_OUT)\n",
    "print(\"SC2 out:\", SC2_OUT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ecd36d9c-cf69-4ad5-8fe9-b8411dc629a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_SECONDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce052d2a-c381-47f4-92fe-378749f0d552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using OE folder: C:\\Users\\ryoi\\Documents\\SpikeSorting\\recordings\\2025-10-01_15-53-19\\Record Node 125\\experiment1\\recording1\n",
      "Available streams:\n",
      "  [0] Record Node 125#Acquisition_Board-100.Rhythm Data\n",
      "  [1] Record Node 125#Acquisition_Board-100.Rhythm Data_ADC\n",
      "Using stream: Record Node 125#Acquisition_Board-100.Rhythm Data\n",
      "OpenEphysBinaryRecordingExtractor: 64 channels - 30.0kHz - 1 segments - 105,877,760 samples \n",
      "                                   3,529.26s (58.82 minutes) - int16 dtype - 12.62 GiB\n",
      "Segments: 1 | Fs: 30000.0 | Ch: 64\n",
      "Recording sliced to first 60s (end_frame=1800000).\n"
     ]
    }
   ],
   "source": [
    "#%% 1) Load Open Ephys & select stream\n",
    "\n",
    "#%% 1) Load Open Ephys & select stream (robust to multi-stream error)\n",
    "\n",
    "from pathlib import Path\n",
    "import re, ast\n",
    "import spikeinterface.extractors as se\n",
    "\n",
    "DATA_PATH = (ROOT_DIR / SESSION_SUBPATH)\n",
    "print(\"Using OE folder:\", DATA_PATH)\n",
    "\n",
    "def discover_oe_stream_names(folder: Path) -> list[str]:\n",
    "    \"\"\"\n",
    "    Return list of OE stream names for this folder.\n",
    "    Works even when SI raises on multi-stream by parsing the error message.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        rec = se.read_openephys(folder)  # may raise if multiple streams\n",
    "        # If we got here, there was only one stream or SI allowed opening without specifying.\n",
    "        # Try public accessor; fall back to _annotations.\n",
    "        get_ann = getattr(rec, \"get_annotation\", None)\n",
    "        if callable(get_ann):\n",
    "            names = get_ann(\"streams_names\") or get_ann(\"stream_names\") or []\n",
    "        else:\n",
    "            ann = getattr(rec, \"_annotations\", {}) or {}\n",
    "            names = ann.get(\"streams_names\") or ann.get(\"stream_names\") or []\n",
    "        # Some SI versions return empty here for single-stream; then get from rec.\n",
    "        if not names:\n",
    "            # As a last resort, print repr and try to infer; otherwise assume single.\n",
    "            names = [getattr(rec, \"stream_name\", None)] if hasattr(rec, \"stream_name\") else []\n",
    "            names = [n for n in names if n]\n",
    "        return names\n",
    "    except ValueError as e:\n",
    "        msg = str(e)\n",
    "        # Typical message contains a Python list right after `stream_names`:\n",
    "        # `stream_names`: ['Record Node ... Rhythm Data', 'Record Node ... Rhythm Data_ADC']\n",
    "        m = re.search(r\"`stream_names`:\\s*(\\[[^\\]]+\\])\", msg)\n",
    "        if m:\n",
    "            try:\n",
    "                names = ast.literal_eval(m.group(1))\n",
    "                return names\n",
    "            except Exception:\n",
    "                pass\n",
    "        # If we can't parse, re-raise with context.\n",
    "        raise\n",
    "\n",
    "# --- Discover stream names safely ---\n",
    "stream_names = []\n",
    "try:\n",
    "    stream_names = discover_oe_stream_names(DATA_PATH)\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Could not discover Open Ephys streams. Set STREAM_NAME manually. Original error: {e}\")\n",
    "\n",
    "if STREAM_NAME is None:\n",
    "    if not stream_names:\n",
    "        raise RuntimeError(\"Could not discover OE stream names; please set STREAM_NAME explicitly.\")\n",
    "    print(\"Available streams:\")\n",
    "    for i, s in enumerate(stream_names):\n",
    "        print(f\"  [{i}] {s}\")\n",
    "    # Heuristic: pick neural data (avoid *_ADC, SYNC)\n",
    "    candidates = [s for s in stream_names\n",
    "                  if (\"Rhythm\" in s or \"Data\" in s) and (\"ADC\" not in s) and (\"SYNC\" not in s)]\n",
    "    STREAM_NAME = candidates[0] if candidates else stream_names[0]\n",
    "\n",
    "print(\"Using stream:\", STREAM_NAME)\n",
    "\n",
    "# --- Open the chosen stream ---\n",
    "recording = se.read_openephys(DATA_PATH, stream_name=STREAM_NAME)\n",
    "print(recording)\n",
    "print(\"Segments:\", recording.get_num_segments(),\n",
    "      \"| Fs:\", recording.get_sampling_frequency(),\n",
    "      \"| Ch:\", recording.get_num_channels())\n",
    "\n",
    "# KS4 requires single segment; keep segment 0 if multiple\n",
    "if recording.get_num_segments() > 1:\n",
    "    recording = recording.select_segments([0])\n",
    "    print(\"Selected segment 0 (single-segment).\")\n",
    "\n",
    "# Optional quick slice\n",
    "if TEST_SECONDS is not None:\n",
    "    fs = recording.get_sampling_frequency()\n",
    "    # Cap end_frame to available frames in segment 0 (handle SI API differences)\n",
    "    n_frames = (recording.get_num_samples(0)\n",
    "                if hasattr(recording, \"get_num_samples\")\n",
    "                else recording.get_num_frames(0))\n",
    "    end_frame = min(int(fs * TEST_SECONDS), n_frames)\n",
    "    recording = recording.frame_slice(0, end_frame)\n",
    "    print(f\"Recording sliced to first {TEST_SECONDS}s (end_frame={end_frame}).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b6c6ed3-1a61-4cce-b8e8-3ba471362355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total channels: 64\n",
      "Tetrodes: 16; first group: [np.str_('CH40'), np.str_('CH38'), np.str_('CH36'), np.str_('CH34')]\n"
     ]
    }
   ],
   "source": [
    "#%% 2) Build tetrode groups (4 channels each) & remove BAD\n",
    "\n",
    "DEV_IDS = list(recording.channel_ids)\n",
    "print(\"Total channels:\", len(DEV_IDS))\n",
    "if len(DEV_IDS) % 4 != 0:\n",
    "    raise ValueError(\"Channel count not divisible by 4; adjust grouping to match your wiring.\")\n",
    "\n",
    "groups = [DEV_IDS[i:i+4] for i in range(0, len(DEV_IDS), 4)]\n",
    "\n",
    "if BAD:\n",
    "    groups = [[ch for ch in g if ch not in BAD] for g in groups]\n",
    "    groups = [g for g in groups if len(g) > 0]\n",
    "    keep = [ch for g in groups for ch in g]\n",
    "    recording = recording.channel_slice(keep_channel_ids=keep)\n",
    "    DEV_IDS = list(recording.channel_ids)\n",
    "    print(\"Removed BAD channels; new channel count:\", len(DEV_IDS))\n",
    "\n",
    "print(f\"Tetrodes: {len(groups)}; first group: {groups[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "011ee9f5-956c-4681-86ad-c1dfde99e318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geometry attached. Locations: (64, 2)\n"
     ]
    }
   ],
   "source": [
    "#%% 3) (Optional) Attach 2Ã—2 tetrode geometry\n",
    "\n",
    "if ATTACH_GEOMETRY:\n",
    "    from probeinterface import Probe\n",
    "    import numpy as np\n",
    "\n",
    "    idx_map = {ch: i for i, ch in enumerate(recording.channel_ids)}\n",
    "    pos = np.zeros((len(idx_map), 2), dtype=float)\n",
    "\n",
    "    pitch = 20.0     # Âµm inside a tetrode\n",
    "    dx, dy = 150.0, 150.0  # Âµm between tetrode blocks\n",
    "\n",
    "    for t, g in enumerate(groups):\n",
    "        base_xy = np.array([[0,0],[pitch,0],[0,pitch],[pitch,pitch]], dtype=float)[:len(g)]\n",
    "        row, col = divmod(t, TETRODES_PER_ROW)\n",
    "        offset = np.array([col*dx, row*dy], dtype=float)\n",
    "        for j, ch in enumerate(g):\n",
    "            pos[idx_map[ch]] = base_xy[j] + offset\n",
    "\n",
    "    pr = Probe(ndim=2)\n",
    "    pr.set_contacts(\n",
    "        positions=pos,\n",
    "        shapes='circle',\n",
    "        shape_params={'radius': 7}\n",
    "    )\n",
    "    # VERY IMPORTANT for SI: map probe contacts to device channel indices\n",
    "    device_inds = np.array([idx_map[ch] for ch in recording.channel_ids], dtype=int)\n",
    "    pr.set_device_channel_indices(device_inds)\n",
    "\n",
    "    recording = recording.set_probe(pr)\n",
    "    print(\"Geometry attached. Locations:\", recording.get_channel_locations().shape)\n",
    "else:\n",
    "    print(\"Geometry attachment skipped (ATTACH_GEOMETRY=False).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "088b32a7-17af-4303-856a-e4c7116e057f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing prepared: bandpass + notch; KS4 with CAR, SC2 without.\n"
     ]
    }
   ],
   "source": [
    "# %% 4) Preprocess (bandpass + notch); per-tetrode CAR for KS4; no CAR for SC2\n",
    "\n",
    "import spikeinterface.preprocessing as spre\n",
    "\n",
    "# --- Bandpass first ---\n",
    "rec_bp = spre.bandpass_filter(recording, freq_min=300, freq_max=6000)\n",
    "\n",
    "# --- Optional: notch out 50 Hz and harmonics (for mains interference) ---\n",
    "for f0 in (50, 100, 150):  # adjust to your mains frequency\n",
    "    rec_bp = spre.notch_filter(rec_bp, freq=f0, q=30)\n",
    "\n",
    "# --- KS4 branch: per-tetrode CAR (grouped median reference) ---\n",
    "rec_ks4 = spre.common_reference(\n",
    "    rec_bp,\n",
    "    reference=\"global\",     # group-wise CAR across tetrodes\n",
    "    operator=\"median\",\n",
    "    groups=groups\n",
    ")\n",
    "\n",
    "# --- SC2 branch: no CAR (does internal whitening) ---\n",
    "rec_sc2 = rec_bp\n",
    "\n",
    "print(\"Preprocessing prepared: bandpass + notch; KS4 with CAR, SC2 without.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1fb2f31-6fb2-4be0-899f-bd8a63dad499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NotchFilterRecording: 64 channels - 30.0kHz - 1 segments - 1,800,000 samples \n",
      "                      60.00s (1.00 minutes) - int16 dtype - 219.73 MiB\n",
      "KS4 chans: 64 | SC2 chans: 64\n",
      "rec_bp NaNs? False dtype: int16\n",
      "rec_ks4 NaNs? False dtype: int16\n",
      "rec_sc2 NaNs? False dtype: int16\n"
     ]
    }
   ],
   "source": [
    "print(rec_bp)\n",
    "print(\"KS4 chans:\", rec_ks4.get_num_channels(), \"| SC2 chans:\", rec_sc2.get_num_channels())\n",
    "import numpy as np\n",
    "import numpy as _np\n",
    "for name, rec in [(\"rec_bp\", rec_bp), (\"rec_ks4\", rec_ks4), (\"rec_sc2\", rec_sc2)]:\n",
    "    s0 = rec.get_traces(start_frame=0, end_frame=min(int(rec.get_sampling_frequency()), rec.get_num_samples()))\n",
    "    print(name, \"NaNs?\", _np.isnan(s0).any(), \"dtype:\", s0.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3566409-1c1c-4f1b-a8a5-aca348a5d15e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write_binary_recording \n",
      "engine=process - n_jobs=1 - samples_per_chunk=30,000 - chunk_memory=3.66 MiB - total_memory=3.66 MiB - chunk_duration=1.00s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9502f3deaf124a6280dcfb390f7fd5f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "write_binary_recording (no parallelization):   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cached KS4 â†’ C:\\Users\\ryoi\\Documents\\SpikeSorting\\ks4_outputs\\cached_ks4_20251025_141602\n",
      "write_binary_recording \n",
      "engine=process - n_jobs=1 - samples_per_chunk=30,000 - chunk_memory=3.66 MiB - total_memory=3.66 MiB - chunk_duration=1.00s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3375146a15640109b1255f8224eea5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "write_binary_recording (no parallelization):   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cached SC2 â†’ C:\\Users\\ryoi\\Documents\\SpikeSorting\\sc2_outputs\\cached_sc2_20251025_141602\n"
     ]
    }
   ],
   "source": [
    "#%% 5) Safe cache helpers (Windows locks) + save caches (timestamped)\n",
    "\n",
    "def safe_rmtree(path: Path, retries: int = 6, wait_s: float = 0.5):\n",
    "    for _ in range(retries):\n",
    "        try:\n",
    "            if path.exists():\n",
    "                shutil.rmtree(path)\n",
    "            return\n",
    "        except PermissionError:\n",
    "            time.sleep(wait_s)\n",
    "    # last try â€” raise if still present/locked\n",
    "    if path.exists():\n",
    "        shutil.rmtree(path)\n",
    "\n",
    "ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "ks4_cache = KS4_OUT / f\"cached_ks4_{ts}\"\n",
    "sc2_cache = SC2_OUT / f\"cached_sc2_{ts}\"\n",
    "\n",
    "# clean then save\n",
    "for cache_dir in (ks4_cache, sc2_cache):\n",
    "    safe_rmtree(cache_dir)\n",
    "\n",
    "rec_ks4_cached = rec_ks4.save(folder=ks4_cache, format=\"binary\", dtype=\"float32\",\n",
    "                              chunk_duration=\"1s\", overwrite=True)\n",
    "print(\"Cached KS4 â†’\", ks4_cache)\n",
    "\n",
    "rec_sc2_cached = rec_sc2.save(folder=sc2_cache, format=\"binary\", dtype=\"float32\",\n",
    "                              chunk_duration=\"1s\", overwrite=True)\n",
    "print(\"Cached SC2 â†’\", sc2_cache)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c8a3fe-da29-46f1-9e5e-5b7edc73836c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort: Computing preprocessing variables.\n",
      "kilosort.run_kilosort: ----------------------------------------\n",
      "kilosort.run_kilosort: N samples: 1800000\n",
      "kilosort.run_kilosort: N seconds: 60.0\n",
      "kilosort.run_kilosort: N batches: 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping common average reference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "kilosort.run_kilosort: Preprocessing filters computed in 0.60s; total 0.60s\n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort: Resource usage after preprocessing\n",
      "kilosort.run_kilosort: ********************************************************\n",
      "kilosort.run_kilosort: CPU usage:    22.40 %\n",
      "kilosort.run_kilosort: Mem used:     87.70 %     |      13.56 GB\n",
      "kilosort.run_kilosort: Mem avail:     1.91 / 15.47 GB\n",
      "kilosort.run_kilosort: ------------------------------------------------------\n",
      "kilosort.run_kilosort: GPU usage:    N/A\n",
      "kilosort.run_kilosort: GPU memory:   N/A\n",
      "kilosort.run_kilosort: ********************************************************\n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort: Computing drift correction.\n",
      "kilosort.run_kilosort: ----------------------------------------\n",
      "kilosort.spikedetect: Re-computing universal templates from data.\n",
      "kilosort.spikedetect: Number of universal templates: 1410\n",
      "kilosort.spikedetect: Detecting spikes...\n",
      "  3%|â–ˆâ–ˆâ–Š                                                                                | 1/30 [00:18<09:08, 18.93s/it]"
     ]
    }
   ],
   "source": [
    "#%% 6) Run Kilosort4\n",
    "\n",
    "import spikeinterface.sorters as ss\n",
    "\n",
    "ks4_params = ss.Kilosort4Sorter.default_params()\n",
    "ks4_params.update({\n",
    "    \"torch_device\": KS4_TORCH_DEVICE,   # \"cpu\" now; switch to \"cuda\" on GPU\n",
    "    \"do_CAR\": False,                    # already did per-tetrode CAR\n",
    "    \"progress_bar\": True,\n",
    "    \"bad_channels\": (BAD or None),\n",
    "    # Optional knobs to pin sensitivity if you like:\n",
    "    # \"Th_universal\": 6,\n",
    "})\n",
    "\n",
    "tag = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "ks4_run = KS4_OUT / f\"ks4_run_{tag}\"\n",
    "safe_rmtree(ks4_run)\n",
    "\n",
    "sorting_ks4 = ss.run_sorter(\n",
    "    \"kilosort4\",\n",
    "    rec_ks4_cached,\n",
    "    folder=ks4_run,                  # SI 0.103 uses folder=\n",
    "    verbose=True,\n",
    "    remove_existing_folder=True,\n",
    "    **ks4_params,\n",
    ")\n",
    "print(\"KS4 units:\", sorting_ks4.get_num_units(), \"| out â†’\", ks4_run)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c37374b-6291-486e-9495-2974db5c6413",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% 7) Run SpyKING Circus 2\n",
    "\n",
    "# Make sure hdbscan is installed in this env (you already did)\n",
    "# pip install hdbscan scikit-learn\n",
    "\n",
    "sc2_params = ss.Spykingcircus2Sorter.default_params()\n",
    "# defaults are generally good; SC2 does CAR/whitening internally\n",
    "\n",
    "sc2_run = SC2_OUT / f\"sc2_run_{tag}\"\n",
    "safe_rmtree(sc2_run)\n",
    "\n",
    "sorting_sc2 = ss.run_sorter(\n",
    "    \"spykingcircus2\",\n",
    "    rec_sc2_cached,\n",
    "    folder=sc2_run,\n",
    "    verbose=True,\n",
    "    remove_existing_folder=True,\n",
    "    **sc2_params,\n",
    ")\n",
    "print(\"SC2 units:\", sorting_sc2.get_num_units(), \"| out â†’\", sc2_run)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcf30c0-20c9-41be-8baf-3804cacb28fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% 8) Create analyzers (SI 0.103 requires this path)\n",
    "\n",
    "from spikeinterface.core import create_sorting_analyzer\n",
    "\n",
    "an_ks4 = create_sorting_analyzer(\n",
    "    sorting=sorting_ks4,\n",
    "    recording=rec_ks4_cached,\n",
    "    folder=KS4_OUT / f\"analyzer_ks4_{tag}\",\n",
    "    overwrite=True,\n",
    ")\n",
    "\n",
    "an_sc2 = create_sorting_analyzer(\n",
    "    sorting=sorting_sc2,\n",
    "    recording=rec_sc2_cached,\n",
    "    folder=SC2_OUT / f\"analyzer_sc2_{tag}\",\n",
    "    overwrite=True,\n",
    ")\n",
    "\n",
    "print(\"Analyzers created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f429248-afa5-49a7-998f-1dc10d701a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% 9) Compute (random_spikes â†’ waveforms â†’ templates â†’ amplitudes â†’ PCs)\n",
    "\n",
    "# KS4 analyzer\n",
    "an_ks4.compute({\"random_spikes\": {\"max_spikes_per_unit\": 500, \"seed\": 42}}, verbose=True)\n",
    "an_ks4.compute(\"waveforms\", ms_before=1.5, ms_after=2.5, dtype=\"float32\",\n",
    "               verbose=True, n_jobs=4, chunk_duration=\"2s\")\n",
    "an_ks4.compute(\"templates\")\n",
    "an_ks4.compute(\"amplitudes\")\n",
    "an_ks4.compute(\"principal_components\")\n",
    "print(\"KS4 analyzer computed.\")\n",
    "\n",
    "# SC2 analyzer (same sequence)\n",
    "an_sc2.compute({\"random_spikes\": {\"max_spikes_per_unit\": 500, \"seed\": 42}}, verbose=True)\n",
    "an_sc2.compute(\"waveforms\", ms_before=1.5, ms_after=2.5, dtype=\"float32\",\n",
    "               verbose=True, n_jobs=4, chunk_duration=\"2s\")\n",
    "an_sc2.compute(\"templates\")\n",
    "an_sc2.compute(\"amplitudes\")\n",
    "an_sc2.compute(\"principal_components\")\n",
    "print(\"SC2 analyzer computed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c903b5ea-b207-485c-87a8-62df8d911a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% 10) Export to Phy\n",
    "\n",
    "from spikeinterface.exporters import export_to_phy\n",
    "\n",
    "phy_ks4 = KS4_OUT / f\"phy_ks4_{tag}\"\n",
    "export_to_phy(an_ks4, output_folder=phy_ks4, remove_if_exists=True)\n",
    "print(\"âœ… Exported Phy (KS4) â†’\", phy_ks4)\n",
    "\n",
    "phy_sc2 = SC2_OUT / f\"phy_sc2_{tag}\"\n",
    "export_to_phy(an_sc2, output_folder=phy_sc2, remove_if_exists=True)\n",
    "print(\"âœ… Exported Phy (SC2) â†’\", phy_sc2)\n",
    "\n",
    "print(\"ðŸŽ‰ All done â€” ready for Phy curation.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (spikeinterface)",
   "language": "python",
   "name": "spikeinterface"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
