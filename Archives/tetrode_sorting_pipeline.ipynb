{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d72a357f-e872-4b48-824d-08613013b9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpikeInterface: 0.103.0\n",
      "Installed sorters: ['kilosort4', 'simple', 'spykingcircus2', 'tridesclous2']\n",
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "#%% 0) Environment + versions (run first)\n",
    "\"\"\"\n",
    "Tetrode sorting pipeline (Open Ephys â†’ SI 0.103 â†’ KS4 & SC2 â†’ Phy)\n",
    "- Robust to multi-stream OE sessions (lets you choose stream)\n",
    "- Real device-ID tetrode grouping (auto by 4, or manual list)\n",
    "- Optional 2Ã—2 tetrode geometry (for nicer Phy plots)\n",
    "- Preprocessing: bandpass + 50/100/150 Hz notch + perâ€‘tetrode CAR\n",
    "- Timestamped caches to avoid Windows file-lock issues\n",
    "- KS4 (CPU by default) and SC2 run in separate, independent blocks\n",
    "- SortingAnalyzer sequence for SI 0.103 (random_spikes â†’ waveforms â†’ templates â†’ amplitudes â†’ PCs)\n",
    "- Phy export per sorter\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "from pathlib import Path\n",
    "import time\n",
    "import shutil\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "import spikeinterface as si\n",
    "import spikeinterface.extractors as se\n",
    "import spikeinterface.preprocessing as spre\n",
    "import spikeinterface.sorters as ss\n",
    "\n",
    "# ----------------------\n",
    "# Quick sanity prints\n",
    "# ----------------------\n",
    "try:\n",
    "    import torch\n",
    "    cuda_ok = torch.cuda.is_available()\n",
    "except Exception:\n",
    "    cuda_ok = False\n",
    "\n",
    "print(\"SpikeInterface:\", si.__version__)\n",
    "print(\"Installed sorters:\", ss.installed_sorters())\n",
    "print(\"CUDA available:\", cuda_ok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc74703b-d650-494c-95a8-319b52f9dcf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data folder: C:\\Users\\ryoi\\Documents\\SpikeSorting\\recordings\\2025-10-01_15-53-19\\Record Node 125\\experiment1\\recording1\n",
      "KS4 outputs â†’ C:\\Users\\ryoi\\Documents\\SpikeSorting\\ks4_outputs\n",
      "SC2 outputs â†’ C:\\Users\\ryoi\\Documents\\SpikeSorting\\sc2_outputs\n",
      "Test duration: 60\n"
     ]
    }
   ],
   "source": [
    "#%% 1) User settings (edit here)\n",
    "# âš™ï¸ Run this in your **spikeinterface** conda env.\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Input recording location ---\n",
    "ROOT_DIR = Path(r\"C:/Users/ryoi/Documents/SpikeSorting/recordings\")\n",
    "SESSION_SUBPATH = Path(r\"2025-10-01_15-53-19/Record Node 125/experiment1/recording1\")\n",
    "DATA_PATH = ROOT_DIR / SESSION_SUBPATH\n",
    "\n",
    "# If your session has multiple streams, set one explicitly or leave None to auto-list\n",
    "STREAM_NAME: str | None = None\n",
    "# e.g. \"Record Node 125#Acquisition_Board-100.Rhythm Data\"\n",
    "\n",
    "# --- Outputs, one folder per sorter ---\n",
    "BASE_DIR = Path(r\"C:/Users/ryoi/Documents/SpikeSorting\")\n",
    "KS4_OUT = BASE_DIR / \"ks4_outputs\"\n",
    "SC2_OUT = BASE_DIR / \"sc2_outputs\"\n",
    "\n",
    "# Create output dirs if missing\n",
    "for d in (KS4_OUT, SC2_OUT):\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- Run a quick test on first N seconds (None = full dataset) ---\n",
    "TEST_SECONDS: int | None = 60\n",
    "\n",
    "# --- Known bad channels (use same ID format as recording.channel_ids) ---\n",
    "BAD: list = []  # e.g. [\"CH59\", \"CH12\"]\n",
    "\n",
    "# --- Optional geometry for nicer Phy plots ---\n",
    "ATTACH_GEOMETRY = True\n",
    "TETRODES_PER_ROW = 8  # grid layout for tetrodes\n",
    "\n",
    "# --- Sorter toggles ---\n",
    "RUN_KS4 = True\n",
    "RUN_SC2 = True\n",
    "\n",
    "# --- KS4 device ('cpu' or 'cuda') ---\n",
    "KS4_TORCH_DEVICE = \"cpu\"\n",
    "\n",
    "# --- Status ---\n",
    "print(\"Using data folder:\", DATA_PATH)\n",
    "print(\"KS4 outputs â†’\", KS4_OUT)\n",
    "print(\"SC2 outputs â†’\", SC2_OUT)\n",
    "print(f\"Test duration: {TEST_SECONDS if TEST_SECONDS else 'FULL recording'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53b13079-55e8-476e-afaa-475578a61b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using stream: Record Node 125#Acquisition_Board-100.Rhythm Data\n",
      "OpenEphysBinaryRecordingExtractor: 64 channels - 30.0kHz - 1 segments - 105,877,760 samples \n",
      "                                   3,529.26s (58.82 minutes) - int16 dtype - 12.62 GiB\n",
      "Segments: 1 | Fs: 30000.0 | Ch: 64\n",
      "Recording sliced to first 60 s for quick run.\n"
     ]
    }
   ],
   "source": [
    "#%% 2) Load Open Ephys recording (pick stream safely)\n",
    "import spikeinterface.extractors as se\n",
    "\n",
    "# If you didn't set STREAM_NAME above, default to the neural stream (not ADC)\n",
    "if STREAM_NAME is None:\n",
    "    STREAM_NAME = \"Record Node 125#Acquisition_Board-100.Rhythm Data\"\n",
    "\n",
    "print(\"Using stream:\", STREAM_NAME)\n",
    "\n",
    "# Load the selected stream\n",
    "recording = se.read_openephys(DATA_PATH, stream_name=STREAM_NAME)\n",
    "print(recording)\n",
    "print(\"Segments:\", recording.get_num_segments(),\n",
    "      \"| Fs:\", recording.get_sampling_frequency(),\n",
    "      \"| Ch:\", recording.get_num_channels())\n",
    "\n",
    "# Kilosort4 requires single segment\n",
    "if recording.get_num_segments() > 1:\n",
    "    recording = recording.select_segments([0])\n",
    "    print(\"Selected segment 0 for single-segment sorting.\")\n",
    "\n",
    "# Optional quick slice for test runs\n",
    "if TEST_SECONDS is not None:\n",
    "    fs = recording.get_sampling_frequency()\n",
    "    recording = recording.frame_slice(0, int(fs * TEST_SECONDS))\n",
    "    print(f\"Recording sliced to first {TEST_SECONDS} s for quick run.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8781fe7c-5ee6-403b-a477-cc41a6b8b09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 24 device IDs: [np.str_('CH40'), np.str_('CH38'), np.str_('CH36'), np.str_('CH34'), np.str_('CH48'), np.str_('CH46'), np.str_('CH44'), np.str_('CH42'), np.str_('CH56'), np.str_('CH54'), np.str_('CH52'), np.str_('CH50'), np.str_('CH58'), np.str_('CH64'), np.str_('CH62'), np.str_('CH60'), np.str_('CH63'), np.str_('CH61'), np.str_('CH59'), np.str_('CH57'), np.str_('CH55'), np.str_('CH53'), np.str_('CH51'), np.str_('CH49')]\n",
      "Total channels: 64\n",
      "Tetrodes: 16 | First group: [np.str_('CH40'), np.str_('CH38'), np.str_('CH36'), np.str_('CH34')]\n"
     ]
    }
   ],
   "source": [
    "#%% 3) Build tetrode groups from real device IDs (auto or manual)\n",
    "DEV_IDS = list(recording.channel_ids)\n",
    "print(\"First 24 device IDs:\", DEV_IDS[:24])\n",
    "print(\"Total channels:\", len(DEV_IDS))\n",
    "\n",
    "# --- Auto-generate tetrode groups of 4 channels each ---\n",
    "if len(DEV_IDS) % 4 != 0:\n",
    "    raise ValueError(\"Channel count not divisible by 4; define custom groups to match your wiring.\")\n",
    "\n",
    "groups = [DEV_IDS[i:i + 4] for i in range(0, len(DEV_IDS), 4)]\n",
    "\n",
    "# --- Manual override example (if you want custom wiring) ---\n",
    "# groups = [\n",
    "#     [\"CH0\", \"CH1\", \"CH2\", \"CH3\"],\n",
    "#     [\"CH4\", \"CH5\", \"CH6\", \"CH7\"],\n",
    "#     # ...\n",
    "# ]\n",
    "\n",
    "# --- Remove known bad channels (if any) ---\n",
    "if BAD:\n",
    "    groups = [[ch for ch in g if ch not in BAD] for g in groups]\n",
    "    groups = [g for g in groups if len(g) > 0]\n",
    "    keep = [ch for g in groups for ch in g]\n",
    "    recording = recording.channel_slice(keep_channel_ids=keep)\n",
    "    DEV_IDS = list(recording.channel_ids)\n",
    "    print(\"Sliced out bad channels. New channel count:\", len(DEV_IDS))\n",
    "\n",
    "print(f\"Tetrodes: {len(groups)} | First group: {groups[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a133ed82-d916-4b43-95ae-2f9a43f75dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geometry attached. Locations shape: (64, 2)\n"
     ]
    }
   ],
   "source": [
    "#%% 4) (Optional) Attach 2Ã—2 tetrode geometry for nicer Phy plots\n",
    "if ATTACH_GEOMETRY:\n",
    "    from probeinterface import Probe\n",
    "    import numpy as np\n",
    "\n",
    "    pitch = 20.0            # Âµm inside tetrode (2x2)\n",
    "    dx, dy = 150.0, 150.0   # Âµm between tetrodes\n",
    "\n",
    "    # Map channel-id -> row index in recording\n",
    "    idx_map = {ch: i for i, ch in enumerate(recording.channel_ids)}\n",
    "    pos = np.zeros((len(idx_map), 2), dtype=float)\n",
    "\n",
    "    # Place each tetrode as a little square on a grid\n",
    "    for t, g in enumerate(groups):\n",
    "        base_xy = np.array([[0, 0], [pitch, 0], [0, pitch], [pitch, pitch]], dtype=float)[:len(g)]\n",
    "        row, col = divmod(t, TETRODES_PER_ROW)\n",
    "        offset = np.array([col * dx, row * dy], dtype=float)\n",
    "        for j, ch in enumerate(g):\n",
    "            pos[idx_map[ch]] = base_xy[j] + offset\n",
    "\n",
    "    # Build probe and (IMPORTANT) set device_channel_indices\n",
    "    pr = Probe(ndim=2)\n",
    "    pr.set_contacts(positions=pos, shapes='circle', shape_params={'radius': 7})\n",
    "    pr.set_device_channel_indices(np.arange(pos.shape[0], dtype=int))  # 0..N-1 in recording order\n",
    "\n",
    "    recording = recording.set_probe(pr)\n",
    "    print(\"Geometry attached. Locations shape:\", recording.get_channel_locations().shape)\n",
    "else:\n",
    "    print(\"Geometry attachment skipped (ATTACH_GEOMETRY=False)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d653b922-dea5-4165-89fa-7cfc3b3cbb58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write_binary_recording \n",
      "engine=process - n_jobs=1 - samples_per_chunk=30,000 - chunk_memory=3.66 MiB - total_memory=3.66 MiB - chunk_duration=1.00s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d6422dc8e2f45bfa00edf18724f3432",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "write_binary_recording (no parallelization):   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write_binary_recording \n",
      "engine=process - n_jobs=1 - samples_per_chunk=30,000 - chunk_memory=3.66 MiB - total_memory=3.66 MiB - chunk_duration=1.00s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97f70ac2718546a7a60823adbe08849a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "write_binary_recording (no parallelization):   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cached KS4 â†’ C:\\Users\\ryoi\\Documents\\SpikeSorting\\ks4_outputs\\cached_ks4_20251024_115046\n",
      "Cached SC2 â†’ C:\\Users\\ryoi\\Documents\\SpikeSorting\\sc2_outputs\\cached_sc2_20251024_115046\n"
     ]
    }
   ],
   "source": [
    "#%% Preprocess + cache with timestamped folders (avoids Windows locks)\n",
    "import spikeinterface.preprocessing as spre\n",
    "from pathlib import Path\n",
    "from time import strftime\n",
    "\n",
    "# Bandpass shared\n",
    "rec_bp = spre.bandpass_filter(recording, freq_min=300, freq_max=6000)\n",
    "\n",
    "# KS4 branch: per-tetrode CAR\n",
    "rec_ks4 = spre.common_reference(rec_bp, reference=\"global\", operator=\"median\", groups=groups)\n",
    "\n",
    "# SC2 branch: no CAR\n",
    "rec_sc2 = rec_bp\n",
    "\n",
    "# Timestamped cache paths (no deletion needed)\n",
    "ts = strftime(\"%Y%m%d_%H%M%S\")\n",
    "ks4_cache = KS4_OUT / f\"cached_ks4_{ts}\"\n",
    "sc2_cache = SC2_OUT / f\"cached_sc2_{ts}\"\n",
    "\n",
    "rec_ks4_cached = rec_ks4.save(folder=ks4_cache, format=\"binary\", dtype=\"float32\",\n",
    "                              chunk_duration=\"1s\")\n",
    "rec_sc2_cached = rec_sc2.save(folder=sc2_cache, format=\"binary\", dtype=\"float32\",\n",
    "                              chunk_duration=\"1s\")\n",
    "\n",
    "print(\"Cached KS4 â†’\", ks4_cache)\n",
    "print(\"Cached SC2 â†’\", sc2_cache)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b320d6d-7744-4646-9355-27ee963446a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Utilities: safe folder delete on Windows ----\n",
    "from pathlib import Path\n",
    "import shutil, time\n",
    "\n",
    "def safe_rmtree(path: Path, retries: int = 5, wait_s: float = 0.6):\n",
    "    \"\"\"Delete a folder with a few retries to dodge Windows file locks.\"\"\"\n",
    "    path = Path(path)\n",
    "    for _ in range(retries):\n",
    "        try:\n",
    "            if path.exists():\n",
    "                shutil.rmtree(path)\n",
    "            return\n",
    "        except PermissionError:\n",
    "            time.sleep(wait_s)\n",
    "    # last tryâ€”raise if still locked\n",
    "    if path.exists():\n",
    "        shutil.rmtree(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f43975e-1e1a-48e8-afbd-d65f237d78d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort: Computing preprocessing variables.\n",
      "kilosort.run_kilosort: ----------------------------------------\n",
      "kilosort.run_kilosort: N samples: 1800000\n",
      "kilosort.run_kilosort: N seconds: 60.0\n",
      "kilosort.run_kilosort: N batches: 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping common average reference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "kilosort.run_kilosort: Preprocessing filters computed in 0.27s; total 0.27s\n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort: Resource usage after preprocessing\n",
      "kilosort.run_kilosort: ********************************************************\n",
      "kilosort.run_kilosort: CPU usage:    40.00 %\n",
      "kilosort.run_kilosort: Mem used:     72.00 %     |      11.13 GB\n",
      "kilosort.run_kilosort: Mem avail:     4.33 / 15.47 GB\n",
      "kilosort.run_kilosort: ------------------------------------------------------\n",
      "kilosort.run_kilosort: GPU usage:    N/A\n",
      "kilosort.run_kilosort: GPU memory:   N/A\n",
      "kilosort.run_kilosort: ********************************************************\n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort: Computing drift correction.\n",
      "kilosort.run_kilosort: ----------------------------------------\n",
      "kilosort.spikedetect: Re-computing universal templates from data.\n",
      "C:\\Users\\ryoi\\AppData\\Local\\anaconda3\\envs\\spikeinterface\\Lib\\site-packages\\threadpoolctl.py:1226: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "kilosort.spikedetect: Number of universal templates: 1224\n",
      "kilosort.spikedetect: Detecting spikes...\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [02:42<00:00,  5.40s/it]\n",
      "kilosort.run_kilosort: drift computed in 167.27s; total 167.85s\n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort: Resource usage after drift correction\n",
      "kilosort.run_kilosort: ********************************************************\n",
      "kilosort.run_kilosort: CPU usage:     0.00 %\n",
      "kilosort.run_kilosort: Mem used:     80.70 %     |      12.47 GB\n",
      "kilosort.run_kilosort: Mem avail:     2.99 / 15.47 GB\n",
      "kilosort.run_kilosort: ------------------------------------------------------\n",
      "kilosort.run_kilosort: GPU usage:    N/A\n",
      "kilosort.run_kilosort: GPU memory:   N/A\n",
      "kilosort.run_kilosort: ********************************************************\n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort: Extracting spikes using templates\n",
      "kilosort.run_kilosort: ----------------------------------------\n",
      "kilosort.spikedetect: Re-computing universal templates from data.\n",
      "kilosort.spikedetect: Number of universal templates: 1224\n",
      "kilosort.spikedetect: Detecting spikes...\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [02:53<00:00,  5.77s/it]\n",
      "kilosort.run_kilosort: 46136 spikes extracted in 178.73s; total 346.59s\n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort: Resource usage after spike detect (univ)\n",
      "kilosort.run_kilosort: ********************************************************\n",
      "kilosort.run_kilosort: CPU usage:    100.00 %\n",
      "kilosort.run_kilosort: Mem used:     84.90 %     |      13.12 GB\n",
      "kilosort.run_kilosort: Mem avail:     2.34 / 15.47 GB\n",
      "kilosort.run_kilosort: ------------------------------------------------------\n",
      "kilosort.run_kilosort: GPU usage:    N/A\n",
      "kilosort.run_kilosort: GPU memory:   N/A\n",
      "kilosort.run_kilosort: ********************************************************\n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort: First clustering\n",
      "kilosort.run_kilosort: ----------------------------------------\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:26<00:00,  3.26s/it]\n",
      "kilosort.run_kilosort: 399 clusters found, in 26.68s; total 373.29s\n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort: Resource usage after first clustering\n",
      "kilosort.run_kilosort: ********************************************************\n",
      "kilosort.run_kilosort: CPU usage:     0.00 %\n",
      "kilosort.run_kilosort: Mem used:     79.00 %     |      12.22 GB\n",
      "kilosort.run_kilosort: Mem avail:     3.24 / 15.47 GB\n",
      "kilosort.run_kilosort: ------------------------------------------------------\n",
      "kilosort.run_kilosort: GPU usage:    N/A\n",
      "kilosort.run_kilosort: GPU memory:   N/A\n",
      "kilosort.run_kilosort: ********************************************************\n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort: Extracting spikes using cluster waveforms\n",
      "kilosort.run_kilosort: ----------------------------------------\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:49<00:00,  1.63s/it]\n",
      "kilosort.run_kilosort: 80194 spikes extracted in 49.16s; total 422.46s\n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort: Resource usage after spike detect (learned)\n",
      "kilosort.run_kilosort: ********************************************************\n",
      "kilosort.run_kilosort: CPU usage:     0.00 %\n",
      "kilosort.run_kilosort: Mem used:     79.60 %     |      12.32 GB\n",
      "kilosort.run_kilosort: Mem avail:     3.15 / 15.47 GB\n",
      "kilosort.run_kilosort: ------------------------------------------------------\n",
      "kilosort.run_kilosort: GPU usage:    N/A\n",
      "kilosort.run_kilosort: GPU memory:   N/A\n",
      "kilosort.run_kilosort: ********************************************************\n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort: Final clustering\n",
      "kilosort.run_kilosort: ----------------------------------------\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:48<00:00,  6.05s/it]\n",
      "kilosort.run_kilosort: 175 clusters found, in 48.42s; total 470.89s\n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort: Merging clusters\n",
      "kilosort.run_kilosort: ----------------------------------------\n",
      "kilosort.run_kilosort: 165 units found, in 1.57s; total 472.46s\n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort: Resource usage after clustering\n",
      "kilosort.run_kilosort: ********************************************************\n",
      "kilosort.run_kilosort: CPU usage:    30.00 %\n",
      "kilosort.run_kilosort: Mem used:     84.00 %     |      12.99 GB\n",
      "kilosort.run_kilosort: Mem avail:     2.48 / 15.47 GB\n",
      "kilosort.run_kilosort: ------------------------------------------------------\n",
      "kilosort.run_kilosort: GPU usage:    N/A\n",
      "kilosort.run_kilosort: GPU memory:   N/A\n",
      "kilosort.run_kilosort: ********************************************************\n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort: Saving to phy and computing refractory periods\n",
      "kilosort.run_kilosort: ----------------------------------------\n",
      "kilosort.run_kilosort: 90 units found with good refractory periods\n",
      "kilosort.run_kilosort: Exporting to Phy took: 1.19s\n",
      "kilosort.run_kilosort: Total runtime: 473.67s = 00:07:54 h:m:s\n",
      "kilosort.run_kilosort: Sorting output saved in: C:\\Users\\ryoi\\Documents\\SpikeSorting\\ks4_outputs\\ks4_run_20251024_115255\\sorter_output.\n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort: Resource usage after saving\n",
      "kilosort.run_kilosort: ********************************************************\n",
      "kilosort.run_kilosort: CPU usage:    53.80 %\n",
      "kilosort.run_kilosort: Mem used:     84.30 %     |      13.04 GB\n",
      "kilosort.run_kilosort: Mem avail:     2.42 / 15.47 GB\n",
      "kilosort.run_kilosort: ------------------------------------------------------\n",
      "kilosort.run_kilosort: GPU usage:    N/A\n",
      "kilosort.run_kilosort: GPU memory:   N/A\n",
      "kilosort.run_kilosort: ********************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kilosort4 run time 473.75s\n",
      "KS4 units: 165 | out â†’ C:\\Users\\ryoi\\Documents\\SpikeSorting\\ks4_outputs\\ks4_run_20251024_115255\n"
     ]
    }
   ],
   "source": [
    "#%% 7A) Run Kilosort4 (if enabled)\n",
    "from time import strftime\n",
    "import spikeinterface.sorters as ss\n",
    "\n",
    "if RUN_KS4:\n",
    "    tag = strftime(\"%Y%m%d_%H%M%S\")\n",
    "    ks4_params = ss.Kilosort4Sorter.default_params()\n",
    "    ks4_params.update({\n",
    "        \"torch_device\": KS4_TORCH_DEVICE,  # \"cpu\" or \"cuda\"\n",
    "        \"do_CAR\": False,                   # we already did CAR in preprocessing\n",
    "        \"progress_bar\": True,\n",
    "    })\n",
    "\n",
    "    ks4_out = KS4_OUT / f\"ks4_run_{tag}\"\n",
    "    safe_rmtree(ks4_out)  # avoids folder lock errors if rerunning\n",
    "\n",
    "    sorting_ks4 = ss.run_sorter(\n",
    "        \"kilosort4\",\n",
    "        rec_ks4_cached,\n",
    "        folder=ks4_out,\n",
    "        verbose=True,\n",
    "        remove_existing_folder=True,\n",
    "        **ks4_params,\n",
    "    )\n",
    "    print(\"KS4 units:\", sorting_ks4.get_num_units(), \"| out â†’\", ks4_out)\n",
    "else:\n",
    "    sorting_ks4 = None\n",
    "    print(\"KS4 skipped (RUN_KS4=False)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceec0941-424e-4682-900d-3b1138a75856",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Run SpyKING CIRCUS 2\n",
    "import spikeinterface.sorters as ss\n",
    "from pathlib import Path\n",
    "from time import strftime\n",
    "import shutil, time\n",
    "\n",
    "# Helper: safe folder delete (avoids Windows file locks)\n",
    "def safe_rmtree(path: Path, retries: int = 3, wait_s: float = 0.5):\n",
    "    for _ in range(retries):\n",
    "        try:\n",
    "            if path.exists():\n",
    "                shutil.rmtree(path)\n",
    "            return\n",
    "        except PermissionError:\n",
    "            time.sleep(wait_s)\n",
    "    if path.exists():\n",
    "        shutil.rmtree(path)\n",
    "\n",
    "# Sanity checks\n",
    "assert 'rec_sc2_cached' in globals(), \"rec_sc2_cached not found. Run the caching cell first.\"\n",
    "assert 'SC2_OUT' in globals(), \"SC2_OUT not defined. Define your output directory first.\"\n",
    "\n",
    "# Default parameters (tweak only keys that exist)\n",
    "sc2_params = ss.Spykingcircus2Sorter.default_params()\n",
    "# Example optional tweaks (uncomment if you want):\n",
    "# sc2_params['job_kwargs'] = {'n_jobs': 4, 'chunk_duration': '2s'}  # parallelism for SC2 internals\n",
    "# sc2_params['general']['debug'] = True  # if you want extra logs\n",
    "\n",
    "tag = strftime(\"%Y%m%d_%H%M%S\")\n",
    "sc2_out = SC2_OUT / f\"sc2_run_{tag}\"\n",
    "safe_rmtree(sc2_out)\n",
    "\n",
    "sorting_sc2 = ss.run_sorter(\n",
    "    \"spykingcircus2\",\n",
    "    rec_sc2_cached,           # â† cached bandpass-only recording (no CAR)\n",
    "    folder=sc2_out,           # (SI 0.103 uses 'folder=')\n",
    "    verbose=True,\n",
    "    remove_existing_folder=True,\n",
    "    **sc2_params,\n",
    ")\n",
    "\n",
    "print(\"SC2 units:\", sorting_sc2.get_num_units(), \"| out â†’\", sc2_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba19e80-6227-426b-83cb-a6367d965fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% 8) Create analyzers (only for the sorters that ran)\n",
    "from spikeinterface.core import create_sorting_analyzer\n",
    "from time import strftime\n",
    "\n",
    "ts = strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "an_ks4, an_sc2 = None, None\n",
    "\n",
    "if sorting_ks4 is not None:\n",
    "    an_ks4 = create_sorting_analyzer(\n",
    "        sorting=sorting_ks4,\n",
    "        recording=rec_ks4_cached,\n",
    "        folder=KS4_OUT / f\"analyzer_ks4_{ts}\",\n",
    "        overwrite=True,\n",
    "    )\n",
    "    print(\"Created analyzer for KS4\")\n",
    "\n",
    "if sorting_sc2 is not None:\n",
    "    an_sc2 = create_sorting_analyzer(\n",
    "        sorting=sorting_sc2,\n",
    "        recording=rec_sc2_cached,\n",
    "        folder=SC2_OUT / f\"analyzer_sc2_{ts}\",\n",
    "        overwrite=True,\n",
    "    )\n",
    "    print(\"Created analyzer for SC2\")\n",
    "\n",
    "print(\"âœ… Analyzer setup complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f776b81-13f9-4bb8-af5d-bf8386edd95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% 9A) Analyzer compute sequence (KS4)\n",
    "\n",
    "if an_ks4 is not None:\n",
    "    print(\"Computing KS4 analyzer extensions...\")\n",
    "\n",
    "    # Step 1 â€” must come first\n",
    "    an_ks4.compute({\"random_spikes\": {\"max_spikes_per_unit\": 500, \"seed\": 42}}, verbose=True)\n",
    "\n",
    "    # Step 2 â€” extract waveforms (use 1.5 ms before, 2.5 ms after)\n",
    "    an_ks4.compute({\n",
    "        \"waveforms\": {\n",
    "            \"ms_before\": 1.5,\n",
    "            \"ms_after\": 2.5,\n",
    "            \"dtype\": \"float32\",\n",
    "        }\n",
    "    }, verbose=True, n_jobs=4, chunk_duration=\"2s\")\n",
    "\n",
    "    # Step 3 â€” build templates (average waveform per unit)\n",
    "    an_ks4.compute(\"templates\", verbose=True)\n",
    "\n",
    "    # Step 4 â€” spike amplitudes\n",
    "    an_ks4.compute(\"spike_amplitudes\", verbose=True)\n",
    "\n",
    "    # Step 5 â€” principal components (for clustering visualization in Phy)\n",
    "    an_ks4.compute({\"principal_components\": {\"n_components\": 5}}, verbose=True)\n",
    "\n",
    "    print(\"âœ… KS4 analyzer fully computed.\")\n",
    "else:\n",
    "    print(\"KS4 analyzer skipped.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ecbabb-5328-4a9c-a001-865d2230ae40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% 9B) Analyzer compute sequence (SC2)\n",
    "\n",
    "if an_sc2 is not None:\n",
    "    print(\"Computing SC2 analyzer extensions...\")\n",
    "    an_sc2.compute({\"random_spikes\": {\"max_spikes_per_unit\": 500, \"seed\": 42}}, verbose=True)\n",
    "    an_sc2.compute({\n",
    "        \"waveforms\": {\"ms_before\": 1.5, \"ms_after\": 2.5, \"dtype\": \"float32\"}\n",
    "    }, verbose=True, n_jobs=4, chunk_duration=\"2s\")\n",
    "    an_sc2.compute(\"templates\", verbose=True)\n",
    "    an_sc2.compute(\"spike_amplitudes\", verbose=True)\n",
    "    an_sc2.compute({\"principal_components\": {\"n_components\": 5}}, verbose=True)\n",
    "    print(\"âœ… SC2 analyzer fully computed.\")\n",
    "else:\n",
    "    print(\"SC2 analyzer skipped.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100699ef-d1c0-4e59-8738-61a244f12d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% 10) Export to Phy\n",
    "\n",
    "from spikeinterface.exporters import export_to_phy\n",
    "from time import strftime\n",
    "\n",
    "ts = strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "if an_ks4 is not None:\n",
    "    phy_ks4 = KS4_OUT / f\"phy_ks4_{ts}\"\n",
    "    export_to_phy(an_ks4, output_folder=phy_ks4, remove_if_exists=True)\n",
    "    print(\"âœ… Exported Phy (KS4) â†’\", phy_ks4)\n",
    "\n",
    "if an_sc2 is not None:\n",
    "    phy_sc2 = SC2_OUT / f\"phy_sc2_{ts}\"\n",
    "    export_to_phy(an_sc2, output_folder=phy_sc2, remove_if_exists=True)\n",
    "    print(\"âœ… Exported Phy (SC2) â†’\", phy_sc2)\n",
    "\n",
    "print(\"ðŸŽ‰ All done â€” ready for Phy curation.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (spikeinterface)",
   "language": "python",
   "name": "spikeinterface"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
